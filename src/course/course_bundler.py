import os
import json
import numpy as np
import chromadb
from chromadb.utils import embedding_functions
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
from datetime import datetime
from collections import OrderedDict, defaultdict

# === ë‚ ì§œ ===
today = datetime.now().strftime("%Y-%m-%d")

# === ê²½ë¡œ ì„¤ì • ===
BASE_DIR = Path(__file__).resolve().parents[2]
ENV_PATH = BASE_DIR / ".env"
COURSE_DIR = BASE_DIR / "data" / "course"
COURSE_DIR.mkdir(parents=True, exist_ok=True)

# === í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ===
load_dotenv(ENV_PATH, override=True)
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

# === session ì •ë ¬ ê¸°ì¤€ í•¨ìˆ˜ (RAG ë™ì¼)
def sort_session_keys(session: dict) -> dict:
    """sessionId(ìˆì„ ê²½ìš°) â†’ deepsearchId â†’ topic â†’ ë‚˜ë¨¸ì§€ ì•ŒíŒŒë²³ìˆœ ì •ë ¬"""
    if not isinstance(session, dict):
        return session

    ordered = []

    # ì£¼ìš” í‚¤ ìˆœì„œ
    if "sessionId" in session:
        ordered.append(("sessionId", session["sessionId"]))
    if "deepsearchId" in session:
        ordered.append(("deepsearchId", session["deepsearchId"]))
    if "topic" in session:
        ordered.append(("topic", session["topic"]))
    if "subTopic" in session:
        ordered.append(("subTopic", session["subTopic"]))

    # ë‚˜ë¨¸ì§€ëŠ” ì•ŒíŒŒë²³ìˆœ
    remaining = sorted(
        [(k, v) for k, v in session.items() if k not in ("sessionId", "deepsearchId", "topic", "subTopic")],
        key=lambda x: x[0].lower()
    )

    return OrderedDict(ordered + remaining)


# === í† í”½ ì •ì˜ ===
TOPIC_SUBTOPICS = {
    "politics": "ëŒ€í†µë ¹ì‹¤ OR êµ­íšŒ OR ì •ë‹¹ OR ë¶í•œ OR êµ­ë°© OR ì™¸êµ OR ë²•ë¥ ",
    "economy": "ê¸ˆìœµ OR ì¦ê¶Œ OR ì‚°ì—… OR ì¤‘ì†Œê¸°ì—… OR ë¶€ë™ì‚° OR ë¬¼ê°€ OR ë¬´ì—­",
    "society": "ì‚¬ê±´ OR êµìœ¡ OR ë…¸ë™ OR í™˜ê²½ OR ì˜ë£Œ OR ë³µì§€ OR ì  ë”",
    "world": "ë¯¸êµ­ OR ì¤‘êµ­ OR ì¼ë³¸ OR ìœ ëŸ½ OR ì¤‘ë™ OR ì•„ì‹œì•„ OR êµ­ì œ",
    "tech": "ì¸ê³µì§€ëŠ¥ OR ë°˜ë„ì²´ OR ë¡œë´‡ OR ë””ì§€í„¸ OR ê³¼í•™ê¸°ìˆ  OR ì—°êµ¬ê°œë°œ OR í˜ì‹ "
}

# === ì„ë² ë”© í•¨ìˆ˜ ===
embedding_fn = embedding_functions.OpenAIEmbeddingFunction(
    api_key=api_key, model_name="text-embedding-3-small"
)

# === ì²˜ë¦¬ ì‹œì‘ ===
for topic, subtopic_query in TOPIC_SUBTOPICS.items():
    print(f"\n[{topic}] ChromaDB ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")

    DB_DIR = BASE_DIR / "data" / "db" / topic
    chroma_client = chromadb.PersistentClient(path=str(DB_DIR))
    collection = chroma_client.get_or_create_collection(
        name=f"{topic}_news",
        embedding_function=embedding_fn
    )

    all_data = collection.get(include=["documents", "embeddings"])
    docs = []

    for doc in all_data["documents"]:
        try:
            parsed = json.loads(doc)
            docs.append(sort_session_keys(parsed))
        except Exception:
            continue

    if not docs:
        print(f"{topic} ë°ì´í„° ì—†ìŒ, ìŠ¤í‚µ.")
        continue

    print(f"{topic} ë‰´ìŠ¤ ê°œìˆ˜: {len(docs)}")

    # === subTopicë³„ë¡œ ê·¸ë£¹í™” ===
    grouped_by_sub = defaultdict(list)
    for d in docs:
        subTopic = d.get("subTopic", "ê¸°íƒ€")
        grouped_by_sub[subTopic].append(d)

    output = []

    # === ê° subTopic ë‹¨ìœ„ë¡œ ì½”ìŠ¤ ìƒì„± ===
    for idx, (subTopic, group_news) in enumerate(grouped_by_sub.items(), start=1):
        # ì„¸ì…˜ ì •ë ¬ & ID ë¶€ì—¬
        for sid, news in enumerate(group_news, start=1):
            news["sessionId"] = sid
            group_news[sid - 1] = sort_session_keys(news)

        # === ìš”ì•½ë¬¸ ê²°í•© ===
        summaries = [
            f"- {n.get('headline', '')}: {n.get('summary', '')[:400]}"
            for n in group_news
        ]
        joined_summary = "\n".join(summaries)

        # === 1ï¸. Course Description ìƒì„± ===
        prompt_course = f"""
ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ë‹¹ì‹ ì€ í•™ìŠµí˜• ë‰´ìŠ¤ ì½˜í…ì¸ ë¥¼ ê¸°íší•˜ëŠ” ì‘ê°€ì´ì ì—ë””í„°ì…ë‹ˆë‹¤.
ì•„ë˜ëŠ” ë¹„ìŠ·í•œ ì£¼ì œì˜ ë‰´ìŠ¤ ì—¬ëŸ¬ ê°œì…ë‹ˆë‹¤.
ì´ ë‰´ìŠ¤ë“¤ì˜ íë¦„ì„ ë°”íƒ•ìœ¼ë¡œ, **ê°€ë…ì„±ì´ ë†’ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì½”ìŠ¤ ì œëª©(courseName)**ê³¼
ì§§ì§€ë§Œ íë¦„ì´ ë³´ì´ëŠ” **ì½”ìŠ¤ ìš”ì•½(courseDescription)**ì„ í•¨ê»˜ ì‘ì„±í•˜ì„¸ìš”.
ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

ğŸ¯ ì‘ì„± ê·œì¹™
1. courseName:
   - ì‹ ë¬¸ í—¤ë“œë¼ì¸ì²˜ëŸ¼ ì§§ê³  ì§ê´€ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (ì˜ˆ: "AIê°€ ë°”ê¾¸ëŠ” ì‚°ì—… í˜„ì¥", "ì§€ë°©ë„ì‹œì˜ ì¬ë„ì•½, ê´€ê´‘ì´ í•´ë‹µì´ë‹¤").
   - ì§€ë‚˜ì¹˜ê²Œ ê¸°ìˆ ì ì´ê±°ë‚˜ ë”±ë”±í•œ í‘œí˜„("ì´ìŠˆ", "ë™í–¥", "ë¶„ì„")ì€ í”¼í•˜ì„¸ìš”.
   - ë…ìê°€ í´ë¦­í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
   - 14~28ì ì´ë‚´ë¡œ ì‘ì„±í•˜ì„¸ìš”.

2. courseDescription:
   - ì½”ìŠ¤ëª… ì•„ë˜ ë“¤ì–´ê°ˆ ì„¤ëª…ë¬¸ìœ¼ë¡œ, ë‰´ìŠ¤ íë¦„ì„ 2~3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”.
   - ë‚´ìš©ì´ ì´ì–´ì§€ëŠ” ì´ì•¼ê¸°ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¨ì£¼ì„¸ìš”.
   - "~ì„ ì´í•´í•œë‹¤" ëŒ€ì‹  "~ì´ í™•ì‚°ë˜ê³  ìˆë‹¤", "~ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë…¼ì˜ê°€ ì´ì–´ì§„ë‹¤" ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹(JSON):
{{
  "courseName": string,
  "courseDescription": string
}}

ë‰´ìŠ¤ ìƒ˜í”Œ ìš”ì•½:
{joined_summary}
"""

        try:
            resp_course = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt_course}],
                response_format={"type": "json_object"}
            )
            meta_course = json.loads(resp_course.choices[0].message.content)
        except Exception as e:
            print(f"[{topic}] {subTopic} course ìƒì„± ì‹¤íŒ¨: {e}")
            meta_course = {
                "courseName": f"{topic}_{subTopic}",
                "courseDescription": "ìë™ ìƒì„± ì‹¤íŒ¨ â†’ ê¸°ë³¸ ì„¤ëª…"
            }

        # === 3ï¸. Keyword ìƒì„± (ì½”ìŠ¤ëª…ì— ì‹¤ì œ í¬í•¨ëœ ë‹¨ì–´ë§Œ) ===
        prompt_kw = f"""
ë‹¹ì‹ ì€ SEO(ê²€ìƒ‰ì—”ì§„ìµœì í™”) ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ ì½”ìŠ¤ëª…ì„ ë³´ê³ , **ì½”ìŠ¤ëª…ì— ì‹¤ì œë¡œ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë§Œ** ì‚¬ìš©í•˜ì—¬
ê²€ìƒ‰ìš© í‚¤ì›Œë“œë¥¼ 3~5ê°œ ì œì‹œí•˜ì„¸ìš”.
ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ğŸ¯ ê·œì¹™:
- ë°˜ë“œì‹œ ì½”ìŠ¤ëª…ì— ì§ì ‘ í¬í•¨ëœ ë‹¨ì–´ë§Œ ì‚¬ìš©
- ì½”ìŠ¤ëª…ì— ì—†ëŠ” ë‹¨ì–´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ ê²ƒ
- ë‹¨ì–´ëŠ” ëª¨ë‘ ëª…ì‚¬ í˜•íƒœ
- ì˜ë¯¸ ì¤‘ë³µ ê¸ˆì§€
- ì¡°ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ ì œê±°

ì¶œë ¥ í˜•ì‹:
{{"keywords": [string, string, string]}}

ì½”ìŠ¤ëª…: "{meta_course['courseName']}"
"""
        try:
            resp_kw = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt_kw}],
                response_format={"type": "json_object"}
            )
            meta_kw = json.loads(resp_kw.choices[0].message.content)
        except Exception as e:
            print(f"[{topic}] {subTopic} keyword ì‹¤íŒ¨: {e}")
            meta_kw = {"keywords": []}

        # === ìµœì¢… course ë°ì´í„° êµ¬ì„± ===
        course_data = OrderedDict([
            ("courseId", idx),
            ("topic", topic),
            ("subTopic", subTopic),
            ("courseName", meta_course.get("courseName", f"{topic}_{subTopic}")),
            ("courseDescription", meta_course.get("courseDescription", "")),
            ("keywords", meta_kw.get("keywords", [])),
            ("sessions", group_news),
        ])
        output.append(course_data)

    # === ì €ì¥ ===
    output_sorted = sorted(output, key=lambda x: x["courseId"])
    output_file = COURSE_DIR / f"{topic}_{today}.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output_sorted, f, ensure_ascii=False, indent=2, sort_keys=False)

    print(f"{topic} â†’ ì½”ìŠ¤ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_file.resolve()}")

print("\n ëª¨ë“  í† í”½ ì½”ìŠ¤ íŒŒì¼ ìƒì„± ì™„ë£Œ.")