import os
import json
import numpy as np
import chromadb
from chromadb.utils import embedding_functions
from pathlib import Path
from dotenv import load_dotenv
from sklearn.cluster import KMeans
from openai import OpenAI
from datetime import datetime
from collections import OrderedDict
from collections import Counter

# === ë‚ ì§œ ===
today = datetime.now().strftime("%Y-%m-%d")

# === ê²½ë¡œ ì„¤ì • ===
BASE_DIR = Path(__file__).resolve().parents[2]
ENV_PATH = BASE_DIR / ".env"
COURSE_DIR = BASE_DIR / "data" / "course"
COURSE_DIR.mkdir(parents=True, exist_ok=True)

# === í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ===
load_dotenv(ENV_PATH, override=True)
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

# === session ì •ë ¬ ê¸°ì¤€ í•¨ìˆ˜ (RAG ë™ì¼)
def sort_session_keys(session: dict) -> dict:
    """sessionId(ìˆì„ ê²½ìš°) â†’ deepsearchId â†’ topic â†’ ë‚˜ë¨¸ì§€ ì•ŒíŒŒë²³ìˆœ ì •ë ¬"""
    if not isinstance(session, dict):
        return session

    ordered = []

    # 1ï¸âƒ£ ì£¼ìš” í‚¤ ìˆœì„œëŒ€ë¡œ ì¶”ê°€ (ì¡´ì¬í•  ê²½ìš°ë§Œ)
    if "sessionId" in session:
        ordered.append(("sessionId", session["sessionId"]))
    if "deepsearchId" in session:
        ordered.append(("deepsearchId", session["deepsearchId"]))
    if "topic" in session:
        ordered.append(("topic", session["topic"]))

    # 2ï¸âƒ£ ë‚˜ë¨¸ì§€ í‚¤ëŠ” ì•ŒíŒŒë²³ ìˆœìœ¼ë¡œ ì •ë ¬
    remaining = sorted(
        [(k, v) for k, v in session.items() if k not in ("sessionId", "deepsearchId", "topic")],
        key=lambda x: x[0].lower()
    )

    return OrderedDict(ordered + remaining)

# === í† í”½ ì •ì˜ ===
TOPIC_SUBTOPICS = {
    "politics": "ëŒ€í†µë ¹ì‹¤ OR êµ­íšŒ OR ì •ë‹¹ OR ë¶í•œ OR í–‰ì • OR êµ­ë°© OR ì™¸êµ OR ë²•ë¥ ",
    "economy": "ê¸ˆìœµ OR ì¦ê¶Œ OR ì‚°ì—… OR ì¤‘ì†Œê¸°ì—… OR ë¶€ë™ì‚°",
    "society": "ì‚¬ê±´ OR êµìœ¡ OR ë…¸ë™ OR í™˜ê²½ OR ì˜ë£Œ OR ë²•ë¥  OR ì  ë”",
    "world": "í•´ì™¸ OR êµ­ì œ OR ì™¸ì‹  OR ë¯¸êµ­ OR ìœ ëŸ½ OR ì¤‘êµ­ OR ì¼ë³¸ OR ì¤‘ë™ OR ì•„ì‹œì•„ OR ì„¸ê³„",
    "tech": "ì¸ê³µì§€ëŠ¥ OR ë¡œë´‡ OR ë°˜ë„ì²´ OR ë””ì§€í„¸ OR ìš°ì£¼ OR ê³¼í•™ê¸°ìˆ  OR ì—°êµ¬ê°œë°œ OR í˜ì‹ "
}

# === ì„ë² ë”© í•¨ìˆ˜ ===
embedding_fn = embedding_functions.OpenAIEmbeddingFunction(
    api_key=api_key, model_name="text-embedding-3-small"
)

# === ì²˜ë¦¬ ì‹œì‘ ===
for topic, subtopic_query in TOPIC_SUBTOPICS.items():
    print(f"\n[{topic}] ChromaDB ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")

    DB_DIR = BASE_DIR / "data" / "db" / topic
    chroma_client = chromadb.PersistentClient(path=str(DB_DIR))
    collection = chroma_client.get_or_create_collection(
        name=f"{topic}_news",
        embedding_function=embedding_fn
    )

    all_data = collection.get(include=["documents", "embeddings"])
    docs, embeddings = [], []

    for doc, emb in zip(all_data["documents"], all_data["embeddings"]):
        try:
            parsed = json.loads(doc)
            docs.append(sort_session_keys(parsed))  # RAG ì •ë ¬ ì¬ì ìš©
            embeddings.append(emb)
        except Exception:
            continue

    if not docs:
        print(f"{topic} ë°ì´í„° ì—†ìŒ, ìŠ¤í‚µ.")
        continue

    X = np.array(embeddings)
    print(f"{topic} ë‰´ìŠ¤ ê°œìˆ˜: {len(docs)}")

    # === 1. KMeans ê¸°ë³¸ ì‹¤í–‰ ===
    n_clusters = 10
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init="auto")
    labels = kmeans.fit_predict(X)

    # === 2. í´ëŸ¬ìŠ¤í„° í¬ê¸° ë¶„í¬ ì¶œë ¥ ===
    counts = Counter(labels)
    print(f"[{topic}] ì´ˆê¸° í´ëŸ¬ìŠ¤í„° ë¶„í¬:", dict(counts))

    # === ê° í´ëŸ¬ìŠ¤í„°ë³„ ì„¸ì…˜ ìˆ˜ ì¶œë ¥
    from collections import Counter
    counts = Counter(labels)
    print(f"\n[{topic}] í´ëŸ¬ìŠ¤í„°ë³„ ì„¸ì…˜ ìˆ˜ ë¶„í¬:")
    for cid, cnt in sorted(counts.items()):
        print(f"  ğŸŸ¢ í´ëŸ¬ìŠ¤í„° {cid}: {cnt}ê°œ ì„¸ì…˜")

    # === ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™” ===
    output = []

    # === ê° ì½”ìŠ¤(cluster) ë‹¨ìœ„ ì²˜ë¦¬ ===
    for cluster_id in range(n_clusters):
        cluster_news = [docs[i] for i, label in enumerate(labels) if label == cluster_id]
        if not cluster_news:
            continue

        # ì„¸ì…˜ ID ìˆ«ì ë¶€ì—¬ (1ë¶€í„° ì‹œì‘)
        for idx, news in enumerate(cluster_news, start=1):
            news["sessionId"] = idx
            cluster_news[idx - 1] = sort_session_keys(news)
            
        # === ì„¸ì…˜ ìš”ì•½ë¬¸ ===
        summaries = [
            f"- {news.get('headline', '')}: {news.get('content', '')[:150]}"
            for news in cluster_news[:7]
        ]
        joined_summary = "\n".join(summaries)

        # === 1ï¸. Course Description ìƒì„± ===
        prompt_course = f"""
ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ë‹¹ì‹ ì€ í•™ìŠµí˜• ë‰´ìŠ¤ ì½˜í…ì¸ ë¥¼ ê¸°íší•˜ëŠ” ì‘ê°€ì´ì ì—ë””í„°ì…ë‹ˆë‹¤.
ì•„ë˜ëŠ” ë¹„ìŠ·í•œ ì£¼ì œì˜ ë‰´ìŠ¤ ì—¬ëŸ¬ ê°œì…ë‹ˆë‹¤.
ì´ ë‰´ìŠ¤ë“¤ì˜ íë¦„ì„ ë°”íƒ•ìœ¼ë¡œ, **ê°€ë…ì„±ì´ ë†’ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì½”ìŠ¤ ì œëª©(courseName)**ê³¼
ì§§ì§€ë§Œ íë¦„ì´ ë³´ì´ëŠ” **ì½”ìŠ¤ ìš”ì•½(courseDescription)**ì„ í•¨ê»˜ ì‘ì„±í•˜ì„¸ìš”.

ğŸ¯ ì‘ì„± ê·œì¹™
1. courseName:
   - ì‹ ë¬¸ í—¤ë“œë¼ì¸ì²˜ëŸ¼ ì§§ê³  ì§ê´€ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (ì˜ˆ: "AIê°€ ë°”ê¾¸ëŠ” ì‚°ì—… í˜„ì¥", "ì§€ë°©ë„ì‹œì˜ ì¬ë„ì•½, ê´€ê´‘ì´ í•´ë‹µì´ë‹¤").
   - ì§€ë‚˜ì¹˜ê²Œ ê¸°ìˆ ì ì´ê±°ë‚˜ ë”±ë”±í•œ í‘œí˜„("ì´ìŠˆ", "ë™í–¥", "ë¶„ì„")ì€ í”¼í•˜ì„¸ìš”.
   - ë…ìê°€ í´ë¦­í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
   - 15~25ì ì´ë‚´ë¡œ ì‘ì„±í•˜ì„¸ìš”.

2. courseDescription:
   - ì½”ìŠ¤ëª… ì•„ë˜ ë“¤ì–´ê°ˆ ì„¤ëª…ë¬¸ìœ¼ë¡œ, ë‰´ìŠ¤ íë¦„ì„ 2~3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”.
   - ë‚´ìš©ì´ ì´ì–´ì§€ëŠ” ì´ì•¼ê¸°ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¨ì£¼ì„¸ìš”.
   - "~ì„ ì´í•´í•œë‹¤" ëŒ€ì‹  "~ì´ í™•ì‚°ë˜ê³  ìˆë‹¤", "~ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë…¼ì˜ê°€ ì´ì–´ì§„ë‹¤" ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹(JSON):
{{
  "courseName": string,
  "courseDescription": string
}}

ë‰´ìŠ¤ ìƒ˜í”Œ ìš”ì•½:
{joined_summary}
"""
        try:
            resp_course = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt_course}],
                response_format={"type": "json_object"}
            )
            meta_course = json.loads(resp_course.choices[0].message.content)
        except Exception as e:
            print(f"[{topic} í´ëŸ¬ìŠ¤í„° {cluster_id}] ì½”ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            meta_course = {
                "courseName": f"{topic} ì´ìŠˆ {cluster_id+1}",
                "courseDescription": "ìë™ ìƒì„± ì‹¤íŒ¨ â†’ ê¸°ë³¸ ì„¤ëª…"
            }

        # === 2ï¸. SubTopic ìƒì„± (ì‚¬ì „ ì •ì˜ëœ í›„ë³´ë§Œ ì„ íƒ) ===
        defined_subtopics = TOPIC_SUBTOPICS[topic].split(" OR ")
        session_texts = "\n".join([n.get("content", "")[:200] for n in cluster_news])

        prompt_subtopic = f"""
ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ë‹¹ì‹ ì€ ë‰´ìŠ¤ ì£¼ì œ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ëŠ” ì—¬ëŸ¬ ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš©ì…ë‹ˆë‹¤.
ì´ ë‰´ìŠ¤ë“¤ì€ ëª¨ë‘ '{topic}' ë¶„ì•¼ì— ì†í•˜ë©°,
ì•„ë˜ì— ì œì‹œëœ ì„¸ë¶€ ì£¼ì œ ëª©ë¡ ì¤‘ì—ì„œ ì´ í´ëŸ¬ìŠ¤í„°ì˜ ë‰´ìŠ¤ë“¤ì´ ê°€ì¥ ë°€ì ‘í•œ í•­ëª© 2~4ê°œë¥¼ ì„ íƒí•˜ì„¸ìš”.

ğŸ¯ ì„ íƒ ê°€ëŠ¥í•œ ì„¸ë¶€ ì£¼ì œ:
{defined_subtopics}

ì¶œë ¥ í˜•ì‹:
{{"subTopic": [string, string, string]}}

ê·œì¹™:
- ë°˜ë“œì‹œ ìœ„ ëª©ë¡ì—ì„œë§Œ ì„ íƒí•  ê²ƒ (ìƒˆë¡œìš´ ë‹¨ì–´ ì¶”ê°€ ê¸ˆì§€)
- ì¤‘ë³µ ì—†ì´ ì¤‘ìš”ë„ ìˆœì„œëŒ€ë¡œ ì •ë ¬

ë‰´ìŠ¤ ìš”ì•½ (ì°¸ê³ ìš©):
{session_texts}
"""
        try:
            resp_sub = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt_subtopic}],
                response_format={"type": "json_object"}
            )
            meta_sub = json.loads(resp_sub.choices[0].message.content)
        except Exception as e:
            print(f"[{topic} í´ëŸ¬ìŠ¤í„° {cluster_id}] subTopic ì‹¤íŒ¨: {e}")
            meta_sub = {"subTopic": [topic]}

        # === 3ï¸. Keyword ìƒì„± (ì½”ìŠ¤ëª…ì— ì‹¤ì œ í¬í•¨ëœ ë‹¨ì–´ë§Œ) ===
        prompt_kw = f"""
ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ë‹¹ì‹ ì€ SEO(ê²€ìƒ‰ì—”ì§„ìµœì í™”) ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ ì½”ìŠ¤ëª…ì„ ë³´ê³ , **ì½”ìŠ¤ëª…ì— ì‹¤ì œë¡œ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë§Œ** ì‚¬ìš©í•˜ì—¬
ê²€ìƒ‰ìš© í‚¤ì›Œë“œë¥¼ 3~5ê°œ ì œì‹œí•˜ì„¸ìš”.

ğŸ¯ ê·œì¹™:
- ë°˜ë“œì‹œ ì½”ìŠ¤ëª…ì— ì§ì ‘ í¬í•¨ëœ ë‹¨ì–´ë§Œ ì‚¬ìš©
- ì½”ìŠ¤ëª…ì— ì—†ëŠ” ë‹¨ì–´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ ê²ƒ
- ë‹¨ì–´ëŠ” ëª¨ë‘ ëª…ì‚¬ í˜•íƒœ
- ì˜ë¯¸ ì¤‘ë³µ ê¸ˆì§€
- ì¡°ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ ì œê±°

ì¶œë ¥ í˜•ì‹:
{{"keywords": [string, string, string]}}

ì½”ìŠ¤ëª…: "{meta_course['courseName']}"
"""
        try:
            resp_kw = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt_kw}],
                response_format={"type": "json_object"}
            )
            meta_kw = json.loads(resp_kw.choices[0].message.content)
        except Exception as e:
            print(f"[{topic} í´ëŸ¬ìŠ¤í„° {cluster_id}] keyword ì‹¤íŒ¨: {e}")
            meta_kw = {"keywords": []}

        # === 4ï¸. ìµœì¢… course ë°ì´í„° êµ¬ì„± (ì •ë ¬ ê³ ì •)
        course_data = OrderedDict([
            ("courseId", cluster_id + 1),
            ("courseName", meta_course.get("courseName", f"{topic} {cluster_id+1}")),
            ("courseDescription", meta_course.get("courseDescription", "")),
            ("subTopic", meta_sub.get("subTopic", [topic])),
            ("keywords", meta_kw.get("keywords", [])),
            ("sessions", cluster_news),  # RAG ì •ë ¬ ìœ ì§€
        ])
        output.append(course_data)

    # === 5ï¸. output ì •ë ¬: courseId ê¸°ì¤€
    output_sorted = sorted(output, key=lambda x: x["courseId"])

    # === 6ï¸. JSON ì €ì¥ (ìˆœì„œ ìœ ì§€)
    output_file = COURSE_DIR / f"{topic}_{today}.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output_sorted, f, ensure_ascii=False, indent=2, sort_keys=False)

    print(f"{topic} â†’ ì½”ìŠ¤ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_file.resolve()}")

print("\n ëª¨ë“  í† í”½ ì½”ìŠ¤ íŒŒì¼ ìƒì„± ì™„ë£Œ.")