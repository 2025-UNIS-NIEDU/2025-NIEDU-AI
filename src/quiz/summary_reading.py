import os, json, re
from datetime import datetime
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).resolve().parents[1]))
from dotenv import load_dotenv
from openai import OpenAI
from keybert import KeyBERT
from sentence_transformers import SentenceTransformer, util
from quiz.select_session import select_session

def generate_summary_reading_quiz(selected_session=None):
    # === í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ===
    load_dotenv(override=True)
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    client = OpenAI(api_key=OPENAI_API_KEY)


    # === ì„¸ì…˜ ì„ íƒ ===
    if selected_session is None:
        selected_session = select_session()

    topic = selected_session["topic"]
    course_id = selected_session["courseId"]
    session_id = selected_session.get("sessionId")
    headline = selected_session.get("headline", "")
    summary = selected_session.get("summary", "")

    print(f"\nì„ íƒëœ ì½”ìŠ¤: {course_id}")
    print(f"sessionId: {session_id}")
    print(f"ì œëª©: {headline}\n")

    # === ìš”ì•½ë¬¸ ì •ì œ ===
    prompt = f"""
    ë„ˆëŠ” 'ë‰´ìŠ¤ ë¬¸í•´ë ¥ í•™ìŠµìš© êµì¬ì— ìˆ˜ë¡ë  ìš”ì•½ë¬¸'ì„ êµì •í•˜ëŠ” ì „ë¬¸ í¸ì§‘ìì´ë‹¤.  
    ë¬¸ì²´ëŠ” ë³´ë„ì²´ê°€ ì•„ë‹Œ ë¶„ì„ì  ì„œìˆ ì²´ë¡œ ìœ ì§€í•œë‹¤.  

    [êµì • ê¸°ì¤€]
    1. ì›ë¬¸ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì •ë³´ë‚˜ ì¶”ì¸¡ì„ ì¶”ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤.  
    2. ì¸ë¬¼, ê¸°ê´€, ìˆ˜ì¹˜ ë“± ì‚¬ì‹¤ ê´€ê³„ëŠ” ì›ë¬¸ê³¼ ì¼ì¹˜í•˜ë„ë¡ ìœ ì§€í•œë‹¤.  
    3. ëª¨ë“  ë¬¸ì¥ì€ ê³¼ê±° ì‹œì œë¡œ í†µì¼í•œë‹¤.  
    4. ë¬¸ì¥ì€ ì¤‘ë¦½ì ì´ê³  ì‚¬ì‹¤ ì„œìˆ í˜•ìœ¼ë¡œ ì‘ì„±í•œë‹¤.  
    - ê°ì •ì , ë¹„ìœ ì , ì¶”ì¸¡ì„± ì–´íœ˜(ì˜ˆ: 'ë…¼ë€', 'ë¹„íŒì ', 'ì¶©ê²©')ëŠ” ì‚­ì œí•œë‹¤.  
    5. ê° ë¬¸ì¥ì€ 25ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ, í•œ ë¬¸ë‹¨ì´ í•œ í˜¸í¡ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ê²Œ í•œë‹¤.
    6. ì¸ë¬¼Â·ê¸°ê´€ì€ ì²˜ìŒ ë“±ì¥í•  ë•Œ ì „ì²´ ëª…ì¹­ìœ¼ë¡œ, ì´í›„ ì•½ì¹­ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤. ë¶€ì¡±í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ëª…ì¹­ ê°„ë‹¨íˆ ë§ë¶™ì¸ë‹¤. 
    7. ëŒ€ëª…ì‚¬(ê·¸, ì´, í•´ë‹¹ ë“±)ì™€ ì§€ì‹œì–´(ì´ë‚ , ì´ì— ëŒ€í•´ ë“±)ëŠ” êµ¬ì²´ì ì¸ ëª…ì‚¬ë¡œ ë°”ê¾¼ë‹¤.  
    8. ë‚ ì§œÂ·ì‹œê°„ í‘œí˜„ì€ ê°€ëŠ¥í•œ í•œ ëª…ì‹œì  í‘œí˜„ìœ¼ë¡œ ë°”ê¾¼ë‹¤. (â€˜ì˜¤ëŠ˜â€™ â†’ â€˜29ì¼â€™)  
    9. ì „ì²´ëŠ” ì‚¬ê±´ì˜ ë°œìƒâ†’ë°œì–¸â†’ê²°ê³¼ ìˆœìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì—´í•œë‹¤.  

    [ì£¼ì˜]
    1. ë‹¨, ë¬¸ì¥ì„ ë§¤ë„ëŸ½ê²Œ ë§Œë“¤ê¸° ìœ„í•´ ì–´ìˆœ ì¡°ì •ì€ í—ˆìš©ëœë‹¤.  
    2. ë„ì–´ ì“°ê¸°ì— ìœ ì˜í•œë‹¤.
    3. ìµœì¢… ì¶œë ¥ì€ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•˜ë¼.

    {{
    "summary": "<êµì •ëœ ìš”ì•½ë¬¸ (ì•½ 200~250ì)>"
    }}

    [ì…ë ¥ ìš”ì•½ë¬¸]
    {summary}
    """
    # === OpenAI Chat Completion í˜¸ì¶œ ===
    response = client.chat.completions.create(
        model="gpt-4o-mini",  # í•„ìš” ì‹œ "gpt-4o"ë‚˜ "gpt-5"ë¡œ ë³€ê²½ ê°€ëŠ¥
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ë‰´ìŠ¤ ë¬¸í•´ë ¥ í•™ìŠµìš© ìš”ì•½ë¬¸ì„ êµì •í•˜ëŠ” ì „ë¬¸ í¸ì§‘ìì´ë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2,
    )

    refined_summary_raw = response.choices[0].message.content.strip()

    # summary ê°’ë§Œ ì¶”ì¶œ
    try:
        refined_summary_json = json.loads(re.sub(r"```json|```", "", refined_summary_raw))
        refined_summary = refined_summary_json.get("summary", "").strip()
    except Exception as e:
        print("JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        refined_summary = refined_summary_raw  

    print("\n==============================")
    print("ì •ì œëœ ìš”ì•½ë¬¸ ê²°ê³¼ (í…ìŠ¤íŠ¸ë§Œ)")
    print("==============================\n")
    print(refined_summary)
    print("\n==============================\n")

    prompt_refine = f"""
    + ë„ˆëŠ” 'ë‰´ìŠ¤ ë¬¸í•´ë ¥ í•™ìŠµìš© êµì¬ì— ìˆ˜ë¡ë  ìš”ì•½ë¬¸'ì„ êµì •í•˜ëŠ” ì „ë¬¸ í¸ì§‘ìì´ë‹¤.  
    ì•„ë˜ [ì…ë ¥ ìš”ì•½ë¬¸]ì„ **ë‹¤ì‹œ ì‘ì„±í•˜ë¼.**  

    [ì§€ì¹¨]
    1. ì‚¬ê±´ì˜ ì „ê°œëŠ” ì›ì¸ â†’ ì „ê°œ â†’ ê²°ê³¼ ìˆœìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì—´í•œë‹¤.
    2. ëˆ„ê°€, ì–¸ì œ, ë¬´ì—‡ì„, ì™œ í–ˆëŠ”ì§€ê°€ ëª…í™•íˆ ë“œëŸ¬ë‚˜ì•¼ í•œë‹¤.
    3. ë¬¸ì²´ëŠ” ì¤‘ë¦½ì ì´ê³  ì‚¬ì‹¤ ì¤‘ì‹¬ì˜ ë³´ë„ì²´ë¡œ ìœ ì§€í•˜ë˜, ì–´ë¯¸ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ì¡°ì •í•œë‹¤.
    4. ì„¸ë¶€ ì •ë³´ê°€ ë¶ˆí™•ì‹¤í•  ë•ŒëŠ” ì¶”ì •í•˜ì§€ ì•ŠëŠ”ë‹¤. ëŒ€ì‹ , ë¬¸ë§¥ì´ ë‹¨ì ˆë˜ì§€ ì•Šë„ë¡ ê¸°ì‚¬ ì†ì—ì„œ í™•ì¸ ê°€ëŠ¥í•œ ê·¼ê±°ë‚˜ ë°œì–¸, ìƒí™© ë¬˜ì‚¬ë¥¼ í™œìš©í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•œë‹¤.
    ë§Œì•½ ì›ì¸ì´ ëª…í™•íˆ ë“œëŸ¬ë‚˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ì´ˆì ì„ ì¸ë¬¼ì˜ ë°œì–¸ ë°°ê²½ì´ë‚˜ ì •ì±…ì  ì˜ë¯¸ë¡œ ì´ë™ì‹œì¼œ ì„œìˆ í•œë‹¤.5. ë¬¸ì¥ ê°„ íë¦„ì´ ë§¤ë„ëŸ½ë„ë¡ ì—°ê²°ì–´ë¥¼ ì¡°ì •í•˜ë˜, ë…¼ë¦¬ë¥¼ ì–µì§€ë¡œ ì´ì–´ ë¶™ì´ì§€ ì•ŠëŠ”ë‹¤.
    6. ì „ì²´ ë¬¸ë‹¨ì€ 200~250ì ë‚´ì™¸ë¡œ êµ¬ì„±í•œë‹¤.

    [ì£¼ì˜]
    1. ìƒˆë¡œìš´ ì‚¬ì‹¤ì´ë‚˜ ì„¸ë¶€ ì •ë³´ë¥¼ ì°½ì‘í•˜ì§€ ë§ë¼.  
    2. ë„ì–´ ì“°ê¸°ì— ìœ ì˜í•œë‹¤. 
    3. ì¶œë ¥ì€ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•˜ë¼.

    {{
    "summary": "<ìì—°ìŠ¤ëŸ½ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ì •ëˆëœ ìš”ì•½ë¬¸>"
    }}

    [ì…ë ¥ ìš”ì•½ë¬¸]
    {refined_summary}
    """

    # === OpenAI Chat Completion í˜¸ì¶œ ===
    response = client.chat.completions.create(
        model="gpt-4o-mini",  # í•„ìš” ì‹œ "gpt-4o"ë‚˜ "gpt-5"ë¡œ ë³€ê²½ ê°€ëŠ¥
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ë‰´ìŠ¤ ë¬¸í•´ë ¥ í•™ìŠµìš© ìš”ì•½ë¬¸ì„ êµì •í•˜ëŠ” ì „ë¬¸ í¸ì§‘ìì´ë‹¤."},
            {"role": "user", "content": prompt_refine}
        ],
    )

    refined_summary_raw = response.choices[0].message.content.strip()
    # summary ê°’ë§Œ ì¶”ì¶œ
    try:
        refined_summary_json = json.loads(re.sub(r"```json|```", "", refined_summary_raw))
        refined_summary = refined_summary_json.get("summary", "").strip()
    except Exception as e:
        print("JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        refined_summary = refined_summary_raw  

    print("\n==============================")
    print("ì •ì œëœ ìš”ì•½ë¬¸ ê²°ê³¼ (í…ìŠ¤íŠ¸ë§Œ)")
    print("==============================\n")
    print(refined_summary)
    print("\n==============================\n")

    # === í•µì‹¬ ì •ë‹µ ì¶”ì¶œ ===
    prompt_answer = f"""
    ë„ˆëŠ” ë‰´ìŠ¤ì˜ í•µì‹¬ì„ ìš”ì•½í•˜ëŠ” ë¶„ì„ê°€ì´ë‹¤.

    ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ì½ê³ ,
    1. ì‚¬ê±´ì˜ **ì£¼ì²´(Actor)** ë¥¼ 1ê°œ ì„ íƒí•˜ê³ ,
    2. ì‚¬ê±´ì˜ **í•µì‹¬ ê°œë…(Object)** ì„ 1ê°œ ì„ íƒí•˜ë¼.
    í•µì‹¬ ê°œë…ì€ **í•˜ë‚˜ì˜ ëª…ì‚¬** ë˜ëŠ” **2~3ì–´ì ˆ ëª…ì‚¬êµ¬** í˜•íƒœë¡œ ì œì‹œí•˜ë¼.

    ì¶œë ¥ í˜•ì‹(JSON):
    {{
    "keywords": [
        {{"word": "ë‹¨ì–´1"}},
        {{"word": "ë‹¨ì–´2"}}
    ]
    }}

    ë‰´ìŠ¤ ìš”ì•½ë¬¸:
    {refined_summary}
    """
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt_answer}],
        temperature=0
    )
    answers_json = json.loads(re.sub(r"```json|```", "", resp.choices[0].message.content.strip()))
    if isinstance(answers_json, dict) and "keywords" in answers_json:
        answers = [a["word"] for a in answers_json["keywords"]]
    elif isinstance(answers_json, list):
        answers = [a["word"] for a in answers_json]
    else:
        raise ValueError(f"ì˜ˆìƒì¹˜ ëª»í•œ JSON êµ¬ì¡°: {answers_json}")
    print(f"ì¤‘ì‹¬ í‚¤ì›Œë“œ(ì •ë‹µ): {answers}")

    # === 2. KeyBERTë¡œ ê´€ë ¨ ë‹¨ì–´ í•„í„°ë§ ===
    anchor_words = answers
    kw_model = KeyBERT(model="jhgan/ko-sroberta-multitask")
    bert_keywords = kw_model.extract_keywords(refined_summary, keyphrase_ngram_range=(1, 2), top_n=15)

    # SentenceTransformer ë¡œ anchor ìœ ì‚¬ë„ í•„í„°ë§
    embed_model = SentenceTransformer("jhgan/ko-sroberta-multitask")

    def is_related(word, anchors, threshold=0.55):
        word_emb = embed_model.encode(word, convert_to_tensor=True)
        sims = [util.cos_sim(word_emb, embed_model.encode(a, convert_to_tensor=True)).item() for a in anchors]
        return max(sims) >= threshold

    related_candidates = [k for k, v in bert_keywords if is_related(k, anchor_words)]
    print("ì •ë‹µê³¼ ê´€ë ¨ëœ ëª…ì‚¬ í›„ë³´:", related_candidates)

    # === 3. LLM í˜¼ë™ ê°€ëŠ¥ì„± í‰ê°€ ===
    prompt_confuse = f"""
    ë„ˆëŠ” ë‰´ìŠ¤ í•™ìŠµìš© ë¬¸ì œë¥¼ ì„¤ê³„í•˜ëŠ” ì „ë¬¸ê°€ì´ë‹¤.

    ë‹¤ìŒ ë‰´ìŠ¤ ìš”ì•½ë¬¸ê³¼ ì •ë‹µ ë‹¨ì–´ë¥¼ ì°¸ê³ í•˜ì—¬,
    ì •ë‹µê³¼ ì£¼ì œì ìœ¼ë¡œ ë°€ì ‘í•˜ì§€ë§Œ ì˜ë¯¸ê°€ ì™„ì „íˆ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´ë“¤ì„ ì˜¤ë‹µ í›„ë³´ë¡œ ì œì‹œí•˜ë¼.

    ë‹¨, ëª¨ë“  ì¶œë ¥ ë‹¨ì–´ëŠ” **ìˆœìˆ˜í•œ ëª…ì‚¬ ë˜ëŠ” ëª…ì‚¬êµ¬ í˜•íƒœ**ì—¬ì•¼ í•˜ë©°,
    ì¡°ì‚¬(ì€, ëŠ”, ì´, ê°€, ì„, ë¥¼ ë“±)ë‚˜ ì–´ë¯¸(í•˜ë‹¤, ë˜ë‹¤ ë“±)ë¥¼ ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤.

    ì˜ˆì‹œ:
    âŒ "ë¬´ì—­ì„", "ê²½ì œì ì¸"  â†’ X  
    âœ… "ë¬´ì—­", "ê²½ì œ", "êµì—­ ì •ì±…"  â†’ O

    [ì˜¤ë‹µ í›„ë³´]
    {bert_keywords}

    [ì…ë ¥]
    ë‰´ìŠ¤ ìš”ì•½ë¬¸:
    {refined_summary}

    ì •ë‹µ ë‹¨ì–´: {answers}

    [ì¶œë ¥ í˜•ì‹]
    {{
    "ranked": [
        {{"word": "<ë‹¨ì–´>", "score": 0.xx, "reason": "<í—·ê°ˆë¦´ ì´ìœ >"}}
    ]
    }}
    """

    resp_confuse = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt_confuse}],
        temperature=0
    )


    # ğŸš¨ ì¤‘ê°„ ì¶œë ¥ (LLM ì›ë¬¸ í™•ì¸)
    print("\n==============================")
    print("LLM ì›ì‹œ ì¶œë ¥ (í˜¼ë™ í›„ë³´ ì›ë³¸)")
    print("==============================\n")
    print(resp_confuse.choices[0].message.content)
    print("\n==============================\n")

    # JSON íŒŒì‹± ì‹œë„
    try:
        llm_ranked_data = json.loads(re.sub(r"```json|```", "", resp_confuse.choices[0].message.content.strip()))
    except json.JSONDecodeError as e:
        print(f"[íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ] JSONDecodeError: {e}")
        print("LLM ì¶œë ¥ ì›ë³¸ ë‹¤ì‹œ í™•ì¸ í•„ìš” â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘")
        raise


    llm_ranked_data = json.loads(re.sub(r"```json|```", "", resp_confuse.choices[0].message.content.strip()))
    llm_ranked = {item["word"]: item["score"] for item in llm_ranked_data["ranked"]}

    print("í˜¼ë™ì–´ í›„ë³´:", list(llm_ranked.keys()))

    # === 4. ì •ê·œí™” ===
    min_s, max_s = min(llm_ranked.values()), max(llm_ranked.values())
    combined = {
        w: round((s - min_s) / (max_s - min_s + 1e-6), 3)
        for w, s in llm_ranked.items()
    }

    # === 5. ìœ ì˜ì–´/ì¤‘ë³µ í•„í„°ë§ ===
    def is_semantically_similar(word, answers, threshold=0.8):
        word_emb = embed_model.encode(word, convert_to_tensor=True)
        for a in answers:
            ans_emb = embed_model.encode(a, convert_to_tensor=True)
            sim = util.cos_sim(word_emb, ans_emb).item()
            if sim >= threshold:
                return True
        return False

    def too_similar(word, answers):
        return any(a in word or word in a for a in answers)

    filtered_combined = {
        w: s for w, s in combined.items()
        if not too_similar(w, answers)
        and not is_semantically_similar(w, answers, threshold=0.8)
    }

    # === 6. ë‚œì´ë„ë³„ ë¶„ë¥˜ ===
    distractors = sorted(filtered_combined.items(), key=lambda x: x[1], reverse=True)[:9]

    while len(distractors) < 9:
        distractors.append(("ê¸°íƒ€", 0.0))

    e_level = distractors[0:3]
    i_level = distractors[3:6]
    n_level = distractors[6:9]

    # === 7. JSON ìƒì„± ===
    def make_keyword_block(level, correct_list, distractors):
        level = level.upper()
        correct_two = correct_list[:2] if len(correct_list) >= 2 else correct_list
        summary_block = refined_summary

        keywords = [{"word": c, "isTopicWord": True} for c in correct_two]
        keywords += [{"word": d[0], "isTopicWord": False} for d in distractors[:3]]

        return {
            "contentType": "SUMMARY_READING",
            "level": level,
            "contents": [
                {
                    "summary": summary_block,
                    "keywords": keywords
                }
            ]
        }

    correct_list = answers[:2] if len(answers) >= 2 else answers
    final_json = [
        make_keyword_block("n", correct_list, n_level),
        make_keyword_block("i", correct_list, i_level),
        make_keyword_block("e", correct_list, e_level)
    ]

    print("\n=== ë³€í™˜ëœ NIEdu í¬ë§· ===")
    print(json.dumps(final_json, ensure_ascii=False, indent=2))

    # === 8. íŒŒì¼ ì €ì¥ ===
    BASE_DIR = Path(__file__).resolve().parents[2]
    QUIZ_DIR = BASE_DIR / "data" / "quiz"
    QUIZ_DIR.mkdir(parents=True, exist_ok=True)
    today = datetime.now().strftime("%Y-%m-%d")

    for block in final_json:
        level = block.get("level", "").upper().strip()
        if not level:
            continue
        file_path = QUIZ_DIR / f"{topic}_{course_id}_{session_id}_SUMMARY_READING_{level}_{today}.json"
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump([block], f, ensure_ascii=False, indent=2)
        print(f"[ì €ì¥ ì™„ë£Œ] {level} ë‹¨ê³„ íŒŒì¼ â†’ {file_path.resolve()}")

#  ì‹¤í–‰
if __name__ == "__main__":
    generate_summary_reading_quiz()